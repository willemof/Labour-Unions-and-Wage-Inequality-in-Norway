"56",
"05",
"50",
"58",
"09",
"78",
"79",
"80",
"62",
"10",
"03",
"81",
"82",
"08",
"11",
"64",
"40",
"06",
"66",
"69",
"12",
"16",
"18",
"13",
"14",
"83",
"41",
"43",
"15",
"84",
"42",
"17",
"46",
"85",
"68",
"19",
"44",
"20",
"52",
"86",
"87",
"55",
"45",
"59",
"24",
"77",
"22",
"23",
"88",
"89",
"21",
"25",
"90",
"27",
"31",
"54",
"29",
"91",
"34",
"28",
"30",
"63",
"33",
"32",
"92",
"26",
"35",
"71",
"72",
"74",
"38",
"70",
"57",
"37",
"60",
"76",
"61",
"75",
"39",
"73",
"65",
"67"
]
}
}
],
"response": {
"format": "json-stat2"
}
}
'
d.tmp <- POST(url , body = data, encode = "json", verbose())
lud <- fromJSONstat(content(d.tmp, "text"))
}
)
)
options(encoding="UTF-8")
library(httr)
library(tidyverse)
library(httr)
library(tinytex)
library(tidyverse)
library(janitor)
library(kableExtra)
library(rjstat)
library(dplyr)
library(stringr)
url <- "https://data.ssb.no/api/v0/no/table/03546/"
# spørring fra konsoll - kan være på en linje
data <- '
{
"query": [
{
"code": "NHO",
"selection": {
"filter": "item",
"values": [
"00",
"01",
"53",
"07",
"02",
"04",
"51",
"56",
"05",
"50",
"58",
"09",
"78",
"79",
"80",
"62",
"10",
"03",
"81",
"82",
"08",
"11",
"64",
"40",
"06",
"66",
"69",
"12",
"16",
"18",
"13",
"14",
"83",
"41",
"43",
"15",
"84",
"42",
"17",
"46",
"85",
"68",
"19",
"44",
"20",
"52",
"86",
"87",
"55",
"45",
"59",
"24",
"77",
"22",
"23",
"88",
"89",
"21",
"25",
"90",
"27",
"31",
"54",
"29",
"91",
"34",
"28",
"30",
"63",
"33",
"32",
"92",
"26",
"35",
"71",
"72",
"74",
"38",
"70",
"57",
"37",
"60",
"76",
"61",
"75",
"39",
"73",
"65",
"67"
]
}
}
],
"response": {
"format": "json-stat2"
}
}
'
d.tmp <- POST(url , body = data, encode = "json", verbose())
lud <- fromJSONstat(content(d.tmp, "text"))
lud <- janitor::clean_names(lud)
lud <- lud %>%
pivot_wider(
names_from = statistikkvariabel) %>%
clean_names()
lud_nominal <- lud %>%
select(-yrkesaktive_medlemer)
lud_nominal <- lud_nominal %>%
pivot_wider(
names_from = landsforening,
values_from = medlemer)%>%
clean_names()
View(lud_nominal)
options(encoding="UTF-8")
library(httr)
library(tidyverse)
library(httr)
library(tinytex)
library(tidyverse)
library(janitor)
library(kableExtra)
library(rjstat)
library(dplyr)
library(stringr)
library(regex)
install.packages("regex")
library(regex)
install.packages("regex")
library(regex)
install.packages("regex")
install.packages("regex")
install.packages("regex")
install.packages("regex")
devtools::install_github("VerbalExpressions/RVerbalExpressions")
library("devtools")
install.packages("RVerbalExpressions")
library(RVerbalExpressions)
library("regex")
install.packages("regex")
install.packages("devtools").
install.packages("devtools")
library("devtools")
devtools::install_github("VerbalExpressions/RVerbalExpressions")
install.packages("regex")
library(RVerbalExpressions)
library("regex")
install.packages("regex")
options(encoding="UTF-8")
library(httr)
library(tidyverse)
library(httr)
library(tinytex)
library(tidyverse)
library(janitor)
library(kableExtra)
library(rjstat)
library(dplyr)
library(stringr)
library(RVerbalExpressions)
library(readtext)
library(rvest)
read_html(https://www.fafo.no/images/pub/2020/20750.pdf)
read_html("https://www.fafo.no/images/pub/2020/20750.pdf")
page <- read_html("https://www.fafo.no/images/pub/2020/20750.pdf")
View(page)
pdf <- download.file("https://www.fafo.no/images/pub/2020/20750.pdf")
download.file("https://www.fafo.no/images/pub/2020/20750.pdf", "./pdf/20750.pdf")
pdf <- readtext("./pdf/20750.pdf")
file.exists("./pdf/20750.pdf")
if(file.exists("./pdf/20750.pdf") == FALSE)
)
if(file.exists("./pdf/20750.pdf") == FALSE)
)
if(file.exists("./pdf/20750.pdf")) == FALSE
if(file.exists("./pdf/20750.pdf"))
)
if(file.exists("./pdf/20750.pdf")) {
next }
if(file.exists("./pdf/20750.pdf")) {
next } else {
download.file("https://www.fafo.no/images/pub/2020/20750.pdf", "./pdf/20750.pdf")
}
if(file.exists("./pdf/20750.pdf")) {
next } else {
download.file("https://www.fafo.no/images/pub/2020/20750.pdf", "./pdf/20750.pdf")
}
pdf <- readtext("./pdf/20750.pdf")
pdf <- read_html("./pdf/20750.pdf")
View(pdf)
install.packages("openPDF")
GET("https://www.fafo.no/images/pub/2020/20750.pdf")
GET("https://www.fafo.no/media/com_netsukii/643.pdf")
url <- "https://www.fafo.no/media/com_netsukii/643.pdf"
file.tmp <- paste0("./pdf/", str_extract(url,"^[0-9]+"),".pdf")
url
str_extract(url)
str_extract(url, "^[0-9]+")
str_extract(url, "^[0-9]+".pdf)
str_extract(url, "^[0-9]+.pdf")
str_extract(url, "^[0-9]+"), ".csv")
str_extract(url, "^[0-9]+") ".pdf")
str_extract(url, "^[0-9]+"))
str_extract(url, "^[0-9]+")
str_extract(url, "^[0-9]")
str_extract(url, "[0-9]")
str_extract(url, "[0-9]+")
str_extract(url, "^[0-9]+")
file.tmp <- paste0("./pdf/", str_extract(url,"[0-9]+"),".pdf")
file.tmp.name <- "str_extract(url,"[0-9]+"),".pdf")"
file.tmp.name <- str_extract(url,"[0-9]+"),".pdf")
file.tmp.name <- str_extract(url,"[0-9]+"),".pdf")
file.tmp <- paste0("./pdf/", str_extract(url,"[0-9]+"),".pdf")
file.tmp.name <- paste0(str_extract(url,"[0-9]+"),".pdf")
url <- "https://www.fafo.no/media/com_netsukii/643.pdf"
file.tmp.name <- paste0(str_extract(url,"[0-9]+"),".pdf")
file.tmp <- paste0("./pdf/", str_extract(url,"[0-9]+"),".pdf")
if(file.exists(file.tmp)) {
next } else {
download.file(url, file.tmp)
}
file.tmp.name <- paste0(str_extract(url,"^[0-9]+"),".pdf")
file.tmp.name <- paste0(str_extract(url,"[0-9]+"),".pdf")
url.list <- c("https://www.fafo.no/media/com_netsukii/643.pdf",
"https://www.fafo.no/images/pub/2020/20750.pdf")
file.tmp.name <- paste0(str_extract(url[i],"[0-9]+"),".pdf")
for(i in 1:nrow(url.list[i])) {
url <- url.list[i]
if(file.exists(file.tmp)) {
next } else {
download.file(url, file.tmp)
}
}
nrow(url.list[i])
nrow(url.list[2])
for(i in 1:nrow(url.list)) {
url <- url.list[i]
if(file.exists(file.tmp)) {
next } else {
download.file(url, file.tmp)
}
}
nrow(url.list)
ncount(url.list)
NCOL(url.list)
NROW(url.list)
for(i in 1:NROW(url.list)) {
url <- url.list[i]
if(file.exists(file.tmp)) {
next } else {
download.file(url, file.tmp)
}
}
#This for-loop downloads the pdfs in url.list
for(i in 1:NROW(url.list)) {
url <- url.list[i]
if(file.exists(file.tmp)) {
next } else {
download.file(url, file.tmp)
}
}
url.list <- c("https://www.fafo.no/media/com_netsukii/643.pdf",
"https://www.fafo.no/images/pub/2020/20750.pdf")
#This for-loop downloads the pdfs in url.list
for(i in 1:NROW(url.list)) {
url <- url.list[i]
if(file.exists(file.tmp)) {
next } else {
download.file(url, file.tmp)
}
}
file.tmp <- paste0("./pdf/", str_extract(url,"[0-9]+"),".pdf")
#This for-loop downloads the pdfs in url.list
for(i in 1:NROW(url.list)) {
url <- url.list[i]
if(file.exists(file.tmp)) {
next } else {
download.file(url, file.tmp)
}
}
#This for-loop downloads the pdfs in url.list
for(i in 1:NROW(url.list)) {
url <- url.list[i]
file.tmp <- paste0("./pdf/", str_extract(url,"[0-9]+"),".pdf")
if(file.exists(file.tmp)) {
next } else {
download.file(url, file.tmp)
}
}
#This for-loop downloads the pdfs in url.list
for(i in 1:NROW(url.list)) {
url <- url.list[i]
file.tmp <- paste0("./pdf/", str_extract(url,"^[0-9]+"),".pdf")
if(file.exists(file.tmp)) {
next } else {
download.file(url, file.tmp)
}
}
str_extract(url,"^[0-9]+"),".pdf"
str_extract(url,"^[0-9]+"),".pdf")
str_extract(url,"^[0-9]+").pdf"
str_extract(url,"[0-9]+$"),".pdf")
str_extract(url,"[0-9]+$"))
str_extract(url,"[0-9]+$")
paste0(str_extract(url,"[0-9]+"),".pdf")
paste0(str_extract(url,"[0-9]+$"),".pdf")
paste0(str_extract(url,"$[0-9]+"),".pdf")
paste0(str_extract(url,"[0-9]+"),".pdf")
paste0(str_extract(url,"[0-9]+"$),".pdf")
paste0(str_extract(url,$"[0-9]+"),".pdf")
paste0(str_extract(url,"[0-9]+"))
paste0(str_extract(url,"[0-9]"))
paste0(str_extract(url,"[0-9]$+"))
paste0(str_extract(url,"[0-9]$"))
paste0(str_extract(url,"[0-9]+"))
paste0(str_extract(url,"$[0-9]"))
paste0(str_extract(url,"\S"))
paste0(str_extract(url,"[0-9]\S"))
paste0(str_extract(url,\d))
str_extract_all(url)
str_extract_all(url, \d)
paste0(str_extract(url,"[0-9]+"))
paste0(str_extract(url,"$"))
paste0(str_extract(url,$))
paste0(str_extract(url,"[0-9]+"))
paste0(str_extract(url,"$+"))
paste0(str_extract(url,"+"))
paste0(str_extract(url,"[0-9]+".pdf")
paste0(str_extract(url,"[0-9]".pdf")
paste0(str_extract(url,"".pdf")
paste0(str_extract(url,".pdf")
)
paste0(str_extract(url,"[0-9]+"".pdf")
paste0(str_extract(url,"[0-9]+"+".pdf")
)
paste0(str_extract(url,"^[0-9]+".pdf")
paste0(str_extract(url,"^[0-9]+".pdf")
str_extract(url, "^[0-9+")
str_extract(url, "^[0-9]+")
str_extract(url, "[0-9]+")
str_extract(url, "^[0-9]")
str_extract(url$, "^[0-9]+")
str_extract(url, "^[0-9]+"),".pdf"
str_extract(url, "^[0-9]+") ".pdf"
str_extract(url, "^[0-9]+")+".pdf"
str_extract(url, "^.pdf")
str_extract(url, ".pdf")
str_extract(url, "+.pdf")
str_extract(url, "*.pdf")
str_extract(url, "$.pdf")
str_extract_all(url,*)
str_extract_all(url)
str_extract_all(url,)
str_extract_all(url,[0-9]+.pdf)
str_extract_all(url,[0-9]+.pdf"")
str_extract_all(url,"[0-9]+.pdf")
str_extract(url,"[0-9]+.pdf")
file.tmp <- paste0("./pdf/", str_extract(url,"[0-9]+.pdf"))
url.list <- c("https://www.fafo.no/media/com_netsukii/643.pdf",
"https://www.fafo.no/images/pub/2020/20750.pdf")
#This for-loop downloads the pdfs in url.list
for(i in 1:NROW(url.list)) {
url <- url.list[i]
file.tmp <- paste0("./pdf/", str_extract(url,"[0-9]+.pdf"))
if(file.exists(file.tmp)) {
next } else {
download.file(url, file.tmp)
}
}
download.file(url, file.tmp)
GET(url)
POST(url)
#This for-loop downloads the pdfs in url.list
for(i in 1:NROW(url.list)) {
url <- url.list[i]
file.tmp <- paste0("./pdf/", str_extract(url,"[0-9]+.pdf"))
if(file.exists(file.tmp)) {
next } else {
download.file(url, file.tmp, mode="wb")
}
}
#This for-loop downloads the pdfs in url.list
for(i in 1:NROW(url.list)) {
url <- url.list[i]
file.tmp <- paste0("./pdf/", str_extract(url,"[0-9]+.pdf"))
if(file.exists(file.tmp)) {
next } else {
download.file(url, file.tmp, mode="wb")
}
}
pdf <- read_html("./pdf/20750.pdf")
pdf2 <- pdf$node
pdf2 <- pdf$doc
install.packages("tabulizer")
install.packages("tabulizer")
install.packages("tabulizer")
